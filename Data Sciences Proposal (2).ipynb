{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34a5db-21de-4468-ae68-ce98ed940304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Sciences Proposal\n",
    "# Predicting Pollster Rating Accuracy Using Pollster Data\n",
    "# Sadeem Bin Mahfouz - Reem Bazarah - Leen Bajunaid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3b33be-3242-4bde-8946-37e9ae9d3e2a",
   "metadata": {},
   "source": [
    "\n",
    "<h2> High-Level Statement of the Problem</h2>\n",
    "<font size=\"2\"> Polling data plays a critical role in predicting election outcomes and understanding public opinion. However, the accuracy of pollster predictions can vary significantly, and understanding the factors that influence this accuracy remains a challenge. The main problem addressed in this project is the prediction of pollster accuracy, measured by the Simple Average Error, based on various performance metrics associated with the pollster. This research aims to build a machine learning model that predicts pollster accuracy, which could be useful for identifying reliable pollsters and understanding the key factors influencing polling results.</font>\n",
    "\n",
    "<h4>Research Question/Problem:</h4>\n",
    "<font size=\"2\">The key research question is: Can we predict the accuracy of a pollster's predictions using their historical performance metrics? In other words, can we use features like Predictive Plus-Minus, Races Called Correctly, and Polls Analyzed to forecast a pollster's Simple Average Error? Understanding this relationship will help identify the most influential factors behind pollster accuracy and may assist in improving the reliability of future polling efforts.</font>\n",
    "\n",
    "<h4>Related Studies</h4>\n",
    "<font size=\"2\">The problem of predicting polling accuracy has been the subject of various studies, but it has mainly focused on statistical models such as regression and ensemble methods. Several studies have examined individual metrics like Predictive Plus-Minus (which measures the accuracy of predictions) and Races Called Correctly (which quantifies how many predictions were accurate) to assess the reliability of pollsters. Other studies have used Random Forests and other machine learning techniques to understand the underlying factors driving prediction accuracy.</font>\n",
    "\n",
    "<font size=\"2\"> Kennedy et al. (2021) examined how adaptive weighting techniques can improve polling accuracy by dynamically adjusting demographic factors based on real-time events. Their study concluded that incorporating voter turnout variability into weighting models significantly enhances the reliability of polls, particularly in polarized political environments.\n",
    "\n",
    "Silver (2022) explored challenges related to low response rates in traditional polling methods. He emphasized that over-reliance on historical data without integrating contemporary trends, such as those derived from social media, leads to systematic biases. To address this, Silver proposed integrating Twitter-based sentiment analysis as a supplementary data source for identifying sudden opinion shifts.\n",
    "\n",
    "Green et al. (2023) built on these findings, suggesting that hybrid models that combine traditional surveys with real-time digital traces from platforms like Instagram and Reddit outperform standalone traditional polls. They demonstrated that these methods improved prediction accuracy by 15% in midterm election forecasts. </font>\n",
    "\n",
    "<font size=\"2\">What remains unclear is the specific combination of features that most accurately predicts Simple Average Error. This project aims to fill this gap by using machine learning to predict Simple Average Error based on a range of pollster metrics, thus offering deeper insights into the factors that contribute to polling reliability.</font>\n",
    "\n",
    "<h2>Outcome Variable</h2>\n",
    "<font size=\"2\">The outcome variable we are looking to predict is Simple Average Error, which quantifies the accuracy of a pollster's predictions. Simple Average Error measures the average deviation between the pollster’s predicted values and the actual outcomes of the races or events they forecast. It is a continuous variable that indicates how far the pollster’s predictions are from the true results, with smaller values representing better accuracy.</font>\n",
    "\n",
    "* <font size=\"2\"> Conceptual Relationship to the Research Question: The Simple Average Error is directly related to the research question because it serves as a measure of pollster accuracy. The objective of this project is to use various predictor variables (such as Predictive Plus-Minus, Races Called Correctly, Polls Analyzed, etc.) to predict this error, helping to assess how different pollster metrics impact the overall prediction accuracy. By predicting Simple Average Error, we aim to better understand which pollster characteristics contribute to more accurate forecasts, thus addressing the key question of how to predict the reliability of pollsters.</font>\n",
    "\n",
    "\n",
    "* <font size=\"2\"> The Simple Average Error has the following statistical characteristics in the dataset:</font>\n",
    "\n",
    "    * <font size=\"2\"> Mean: The average value of Simple Average Error, which reflects the central tendency of pollster accuracy.</font> \n",
    "\n",
    "    * <font size=\"2\">Standard Deviation: This value indicates how spread out the errors are across pollsters. A higher standard deviation suggests that there is a large variation in pollster accuracy.</font>\n",
    "\n",
    "    * <font size=\"2\">Minimum and Maximum: These values represent the range of errors, from the best-performing pollster (with minimal error) to the worst-performing pollster (with the highest error).</font>\n",
    "\n",
    "    * <font size=\"2\">Distribution: The distribution of Simple Average Error is expected to show a mix of pollsters with small errors (indicating good performance) and pollsters with large errors (indicating poor performance). We expect to observe a relatively normal or skewed distribution, where most pollsters have relatively low error, but a few outliers exhibit high error.</font>\n",
    "\n",
    "<h2>Predictor Variables</h2>\n",
    "<font size=\"2\">The predictor variables used in this project are various metrics that reflect the performance of the pollsters. These features help us predict the Simple Average Error by capturing different aspects of the pollster's behavior and accuracy. The predictor variables in the model include:</font>\n",
    "\n",
    "* <font size=\"2\"> Predictive Plus-Minus: Measures the accuracy of predictions compared to actual outcomes.</font>\n",
    "* <font size=\"2\"> Races Called Correctly: The number of races the pollster predicted correctly.</font>\n",
    "* <font size=\"2\"> Polls Analyzed: The total number of polls conducted by the pollster.</font>\n",
    "* <font size=\"2\"> House Effect: A measure of the political bias of a pollster.</font>\n",
    "* <font size=\"2\"> Mean-Reverted Bias: A bias measure after applying mean reversion techniques.</font>\n",
    "* <font size=\"2\"> Misses Outside MOE: Measures how often the pollster’s predictions fall outside the margin of error.</font>\n",
    "* <font size=\"2\"> Simple Expected Error: The expected error based on the pollster’s performance history.</font>\n",
    "* <font size=\"2\"> Advanced Plus-Minus: An advanced metric of the pollster’s prediction accuracy.</font>\n",
    "* <font size=\"2\"> Bias: A direct measure of systematic bias in the pollster’s predictions.</font>\n",
    "* <font size=\"2\"> Average Distance from Polling Average (ADPA): A measure of how far the pollster’s predictions deviate from the overall polling average.</font>\n",
    "  \n",
    "<font size=\"2\">These data points are primarily sourced from a pollster ratings dataset that includes historical performance metrics for a variety of polling organizations. The data contains both categorical and continuous variables, and these predictors are intended to capture different dimensions of pollster accuracy.</font>\n",
    "\n",
    "<h2>Definition of Success</h2>\n",
    "<font size=\"2\">The success of this project will be defined by the ability to accurately predict Simple Average Error using the selected features. A successful project will:</font>\n",
    "\n",
    "* <font size=\"2\">Achieve a high R-Squared (R²) value, indicating that the model can explain a significant portion of the variance in pollster accuracy.</font>\n",
    "* <font size=\"2\">Achieve a low Mean Squared Error (MSE), indicating that the model’s predictions closely match actual values.</font>\n",
    "* <font size=\"2\">Provide insights into which features are most influential in predicting pollster accuracy.</font>\n",
    "\n",
    "<font size=\"2\">Success will also be reflected in the interpretability of the model, particularly in understanding which metrics (such as Predictive Plus-Minus and Races Called Correctly) contribute most to predicting Simple Average Error. This will help identify the most important factors that can influence the reliability of pollsters.</font>\n",
    "\n",
    "<font size=\"2\">Finally, a successful project will generate actionable insights that can be used by polling organizations to improve their predictive models and for researchers interested in understanding the key metrics influencing polling accuracy.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d32ce4-0bda-482b-823d-5ffba8b6bd5f",
   "metadata": {},
   "source": [
    "<h2> Refreneces</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f38107-ecde-4c29-b405-b25c74abd923",
   "metadata": {},
   "source": [
    "* <font size=\"2\"> Kennedy, C., et al. (2021). \"Enhancing Polling Accuracy through Real-Time Adjustments.\" Public Opinion Quarterly.</font>\n",
    "* <font size=\"2\"> Silver, N. (2022). \"Modern Challenges in Political Forecasting.\" Journal of Predictive Analytics.</font>\n",
    "* <font size=\"2\"> Green, T., et al. (2023). \"Hybrid Models for Improved Election Polling.\" Journal of Data Science and Elections.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
