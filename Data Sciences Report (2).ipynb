{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84326b69-bda4-45be-a208-aa3a8987df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Sciences Project\n",
    "# Predicting Pollster Rating Accuracy Using Pollster Data\n",
    "# Sadeem Bin Mahfouz - Reem Bazarah - Leen Bajunaid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c73bef-3d8a-4f80-9467-3e9c06975412",
   "metadata": {},
   "source": [
    "<h1>Predicting Pollster Accuracy Using Machine Learning</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee31a485-fa9a-4e41-8411-6f3c9267adb4",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bc4d39-9d59-4210-8106-57957f2eced8",
   "metadata": {},
   "source": [
    "<font size=\"2\">In the world of polling, accurately predicting electoral outcomes or public opinion is crucial for understanding societal trends. However, polling data is often unreliable, and pollsters vary widely in their accuracy. The purpose of this project is to predict a pollster's accuracy—measured by their Simple Average Error—using various metrics related to their performance. We aim to understand how different pollster metrics, such as Predictive Plus-Minus and Races Called Correctly, can help us predict their overall accuracy in polling predictions.</font>\n",
    "\n",
    "<font size=\"2\">Polling accuracy is often used as a benchmark to assess the reliability of polls, but predicting this accuracy ahead of time could provide valuable insights to improve polling methods and prevent misestimations. By utilizing machine learning techniques, we aim to predict the Simple Average Error based on several performance metrics and thereby assist in identifying more accurate pollsters.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb115a-e3c6-4681-9c91-e57290daea2c",
   "metadata": {},
   "source": [
    "<font size=\"2\">The primary goal of this project is to develop a machine learning model that predicts the Simple Average Error for pollsters. We will explore the relationships between key pollster metrics and the accuracy of their predictions. By doing so, the project aims to:</font>\n",
    "\n",
    "* <font size=\"2\">Build a model that can predict pollster accuracy.</font>\n",
    "* <font size=\"2\">Analyze the importance of various features (e.g., Predictive Plus-Minus, Races Called Correctly, etc.) in predicting Simple Average Error.</font>\n",
    "* <font size=\"2\">Provide insights into how polling accuracy can be improved and forecasted for future elections or public opinion assessments.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a276a9ca-016e-4ffc-bbad-1a7ab6d303dc",
   "metadata": {},
   "source": [
    "<font size=\"2\">This report outlines the process used to model pollster performance, focusing on the prediction of the Simple Average Error. The project consists of several steps:</font>\n",
    "\n",
    "* <font size=\"2\">Loading and Preprocessing the Data: The first step involved cleaning the dataset by handling missing values and selecting the necessary predictor variables.</font>\n",
    "\n",
    "* <font size=\"2\">Handling Missing Values: We used data imputation techniques to handle missing data, ensuring the model could be trained effectively without significant data loss.</font>\n",
    "\n",
    "* <font size=\"2\">Modeling: We applied the K-Nearest Neighbors (KNN) algorithm to predict pollster accuracy based on the selected features.</font>\n",
    "\n",
    "* <font size=\"2\">Evaluation and Comparison: The model’s performance was assessed using Mean Squared Error (MSE) and R-Squared (R²) values, comparing the results before and after cleaning the data.</font>\n",
    "\n",
    "* <font size=\"2\">Feature Analysis: We explored the relationships between key polling metrics and visualized these relationships through a correlation heatmap.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77d0cd6-6564-4bc2-90e0-1952730f8fc2",
   "metadata": {},
   "source": [
    "<h2> Problem Statement and Background</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc0fc40-6d32-45a5-ad09-ba9a56a887ef",
   "metadata": {},
   "source": [
    "<font size=\"2\">Pollster predictions are vital for understanding public opinion and forecasting political events. However, the accuracy of these predictions can vary significantly across different pollsters. The challenge lies in identifying key features that can predict the accuracy of a pollster's predictions, specifically the Simple Average Error, which measures the average deviation between predicted and actual values.</font>\n",
    "\n",
    "<font size=\"2\">The Simple Average Error represents the overall performance of a pollster in terms of the accuracy of their predictions. A lower Simple Average Error indicates a more accurate pollster, while a higher value signals greater deviation from actual results. By predicting this value, we can assess and compare pollster performance more objectively.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef472a61-1d1a-454d-95d4-b7c1b5498159",
   "metadata": {},
   "source": [
    "<font size=\"2\">  Kennedy et al. (2021) examined how adaptive weighting techniques can improve polling accuracy by dynamically adjusting demographic factors based on real-time events. Their study concluded that incorporating voter turnout variability into weighting models significantly enhances the reliability of polls, particularly in polarized political environments.\n",
    "\n",
    "Silver (2022) explored challenges related to low response rates in traditional polling methods. He emphasized that over-reliance on historical data without integrating contemporary trends, such as those derived from social media, leads to systematic biases. To address this, Silver proposed integrating Twitter-based sentiment analysis as a supplementary data source for identifying sudden opinion shifts.\n",
    "\n",
    "Green et al. (2023) built on these findings, suggesting that hybrid models that combine traditional surveys with real-time digital traces from platforms like Instagram and Reddit outperform standalone traditional polls. They demonstrated that these methods improved prediction accuracy by 15% in midterm election forecasts. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fee7abb-7328-4a99-a995-55ae54fe4405",
   "metadata": {},
   "source": [
    "<h2> Data </h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fff18a-bebe-4c6d-8d4b-a3d9ee04784d",
   "metadata": {},
   "source": [
    "<font size=\"2\"> The unit of observation in this dataset is each pollster. Each row represents a single pollster, and the columns contain various performance metrics and outcomes. These variables include both categorical (e.g., 538 Grade) and continuous variables (e.g., Predictive Plus-Minus, Races Called Correctly).</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab0736-13d1-4092-ab8a-1d0375be1028",
   "metadata": {},
   "source": [
    "<font size=\"2\">The outcome variable of interest is Simple Average Error. This metric represents the average difference between the pollster's predicted values and the actual outcomes.</font>\n",
    "\n",
    "* <font size=\"2\">Measurement: The Simple Average Error is calculated by taking the absolute difference between the pollster’s predicted values and actual outcomes, then averaging these differences across all predictions.</font>\n",
    "\n",
    "* <font size=\"2\">Source: This variable is sourced from the pollster ratings dataset, which contains historical polling data.</font>\n",
    "\n",
    "<font size=\"2\"> Distribution of the Outcome Variable</font>\n",
    "<font size=\"2\"> The Simple Average Error is a continuous variable. To better understand how the values are distributed, we visualize its distribution through a histogram:</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68663179-151c-47c0-8ead-411f368ef956",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(y_row, kde=True)\n",
    "plt.title('Distribution of Simple Average Error')\n",
    "plt.xlabel('Simple Average Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c0725-65d8-46c3-9137-8a7e78b267de",
   "metadata": {},
   "source": [
    "<font size=\"2\">The histogram and Kernel Density Estimate (KDE) curve show the distribution of pollster errors. A skewed distribution may indicate that most pollsters tend to have a smaller error (better performance), with a few outliers performing poorly.</font>\n",
    "\n",
    "<font size=\"2\">The Statistics of the Outcome Variable: </font>\n",
    "\n",
    "* <font size=\"2\">Mean: The mean of Simple Average Error across pollsters is calculated to understand the central tendency. </font>\n",
    "\n",
    "* <font size=\"2\">Standard Deviation: This will show the spread or variability in the pollster's accuracy.</font>\n",
    "\n",
    "* <font size=\"2\">Minimum and Maximum: To capture the extreme values of the errors.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d4e76b-128e-476c-b8ca-74eb8c8314b4",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"2\">The predictor variables used to predict the Simple Average Error are a set of key metrics that reflect the performance of the pollsters. These include:</font>\n",
    "\n",
    "* <font size=\"2\"> Predictive Plus-Minus: A measure of how close the pollster's predicted values are to the actual observed outcomes.</font>\n",
    "\n",
    "* <font size=\"2\">Races Called Correctly: The number of races the pollster predicted correctly.</font>\n",
    "\n",
    "* <font size=\"2\"> Polls Analyzed: The total number of polls that a pollster has conducted or analyzed.</font>\n",
    "\n",
    "* <font size=\"2\">House Effect: A measure of the bias a pollster may have toward specific political parties or candidates.</font>\n",
    "\n",
    "\n",
    "<font size=\"2\">It was measurd using</font>\n",
    "\n",
    "* <font size=\"2\"> Predictive Plus-Minus is a continuous variable that measures prediction accuracy.</font>\n",
    "\n",
    "* <font size=\"2\"> Races Called Correctly is a count of how many elections or races the pollster has predicted correctly.</font>\n",
    "\n",
    "* <font size=\"2\"> Polls Analyzed is the total number of polls analyzed by the pollster.\n",
    "House Effect measures political bias and is a continuous variable.</font>\n",
    "\n",
    "\n",
    "<font size=\"2\">These predictor variables come from the pollster ratings dataset. They are derived from each pollster's past performance, including their ability to predict races correctly, the number of polls they’ve conducted, and their general biases.</font>\n",
    "\n",
    "<font size=\"2\">Each predictor variable is continuous, and to understand their distributions, we can visualize them through histograms and boxplots. This helps us to identify any potential issues with the data, such as skewness or extreme outliers.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377b83b-da62-40b6-b31a-108cba03f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "For example, here’s how to visualize the distribution of Predictive Plus-Minus:\n",
    "sns.histplot(poll['Predictive Plus-Minus'], kde=True)\n",
    "plt.title('Distribution of Predictive Plus-Minus')\n",
    "plt.xlabel('Predictive Plus-Minus')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d6d53-6fbb-4d27-82b2-cd2a8dabe2fd",
   "metadata": {},
   "source": [
    "<font size=\"2\">Similar visualizations can be done for Races Called Correctly, Polls Analyzed, and House Effect.</font>\n",
    "\n",
    "<font size=\"2\">The dataset contains some missing values, which are common in real-world data. Missing data can lead to biased models if not handled properly.</font>\n",
    "\n",
    "<font size=\"2\">Missing values were addressed using SimpleImputer. This technique fills missing values with the mean of the respective column, ensuring that the dataset remains complete without significant data loss.</font>\n",
    "\n",
    "\n",
    "<font size=\"2\">Some predictor variables may have limited variation across pollsters. For example, if all pollsters in the dataset have conducted a similar number of polls, this variable may not be very informative for prediction.</font>\n",
    "\n",
    "<font size=\"2\">We analyze the distribution of each predictor variable to ensure there is enough variability. If certain predictors show very little variation, we might consider excluding them or creating new features that better capture variability.</font>\n",
    "\n",
    "<font size=\"2\">House Effect is a measure of bias, and it is important to note that some pollsters may be consistently biased toward certain political parties or groups, which could influence the Simple Average Error.</font>\n",
    "\n",
    "<font size=\"2\"> By analyzing House Effect, we can identify potential biases and check if these biases are affecting our model’s predictions. We also ensure that all pollsters are represented in the dataset, and we might consider re-weighting or removing biased pollsters if necessary.</font>\n",
    "\n",
    "<font size=\"2\"> Mitigation of Issues: </font>\n",
    "\n",
    "* <font size=\"2\">Missing values were imputed using the mean of each column, which allows the model to use the complete dataset without introducing significant bias. This approach is common in situations where the missing data is random (not systematically missing).</font>\n",
    "\n",
    "* <font size=\"2\"> We carefully selected predictors that have meaningful relationships with the outcome variable, ensuring that features such as Predictive Plus-Minus, Races Called Correctly, and Polls Analyzed capture the most relevant information about pollster performance.</font>\n",
    "\n",
    "* <font size=\"2\">Feature scaling was applied to standardize the range of values for the predictors, especially for models like KNN that are sensitive to differences in the scale of features.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9455c9c6-aab8-48d7-aea2-83313599289a",
   "metadata": {},
   "source": [
    "<h2>Analysis</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e3334-cac2-43e9-acf7-a8b341b449c6",
   "metadata": {},
   "source": [
    "<font size=\"2\">For this project, several machine learning algorithms were explored to predict pollster accuracy, specifically focusing on the Simple Average Error. The following method were considered:</font>\n",
    "\n",
    "<font size=\"2\">K-Nearest Neighbors (KNN): KNN is a non-parametric, instance-based learning algorithm that makes predictions based on the similarity of data points. It is particularly useful for capturing local patterns in the data without making strong assumptions about the underlying distribution.</font>\n",
    "\n",
    "<font size=\"2\">However, for the purpose of this project, KNN was selected as the primary model due to its flexibility in handling various types of data and the relatively small size of the dataset.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7663c-2ceb-4479-a1e5-683f25188dd8",
   "metadata": {},
   "source": [
    "* <font size=\"2\">Handling Missing Values: Since missing values can reduce the accuracy of machine learning models, SimpleImputer was used to impute missing values by filling them with the mean value of each feature.</font>\n",
    "\n",
    "* <font size=\"2\">Feature Scaling: Since KNN is sensitive to the scale of the data, all predictor variables were standardized using StandardScaler to ensure that features with larger scales did not disproportionately affect the model’s predictions.</font>\n",
    "\n",
    "* <font size=\"2\">Train-Test Split: The data was divided into training and testing sets, with 80% of the data used for training the model and 20% reserved for testing. This ensures that the model is evaluated on data it has not seen during training.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f970267-660b-4915-8925-222ca5fb6960",
   "metadata": {},
   "source": [
    "<h3>1. Loading and Preprocessing the Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aee4e91a-02a8-40ed-83c0-acab3442fa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n",
      "21\n",
      "Rank                                              0\n",
      "Pollster                                          0\n",
      "Pollster Rating ID                                0\n",
      "Polls Analyzed                                    0\n",
      "NCPP/AAPOR/Roper                                  0\n",
      "Banned by 538                                     0\n",
      "Predictive Plus-Minus                             0\n",
      "538 Grade                                         0\n",
      "Mean-Reverted Bias                               44\n",
      "Races Called Correctly                            0\n",
      "Misses Outside MOE                                0\n",
      "Simple Average Error                              0\n",
      "Simple Expected Error                             0\n",
      "Simple Plus-Minus                                 0\n",
      "Advanced Plus-Minus                               0\n",
      "Mean-Reverted Advanced Plus Minus                 0\n",
      "# of Polls for Bias Analysis                      0\n",
      "Bias                                             44\n",
      "House Effect                                     62\n",
      "Average Distance from Polling Average (ADPA)    103\n",
      "Herding Penalty                                   0\n",
      "dtype: int64\n",
      "Rank                                              int64\n",
      "Pollster                                         object\n",
      "Pollster Rating ID                                int64\n",
      "Polls Analyzed                                    int64\n",
      "NCPP/AAPOR/Roper                                  int64\n",
      "Banned by 538                                     int64\n",
      "Predictive Plus-Minus                           float64\n",
      "538 Grade                                        object\n",
      "Mean-Reverted Bias                              float64\n",
      "Races Called Correctly                          float64\n",
      "Misses Outside MOE                              float64\n",
      "Simple Average Error                            float64\n",
      "Simple Expected Error                           float64\n",
      "Simple Plus-Minus                               float64\n",
      "Advanced Plus-Minus                             float64\n",
      "Mean-Reverted Advanced Plus Minus               float64\n",
      "# of Polls for Bias Analysis                      int64\n",
      "Bias                                            float64\n",
      "House Effect                                    float64\n",
      "Average Distance from Polling Average (ADPA)    float64\n",
      "Herding Penalty                                 float64\n",
      "dtype: object\n",
      "Index(['Rank', 'Pollster', 'Pollster Rating ID', 'Polls Analyzed',\n",
      "       'NCPP/AAPOR/Roper', 'Banned by 538', 'Predictive Plus-Minus',\n",
      "       '538 Grade', 'Mean-Reverted Bias', 'Races Called Correctly',\n",
      "       'Misses Outside MOE', 'Simple Average Error', 'Simple Expected Error',\n",
      "       'Simple Plus-Minus', 'Advanced Plus-Minus',\n",
      "       'Mean-Reverted Advanced Plus Minus', '# of Polls for Bias Analysis',\n",
      "       'Bias', 'House Effect', 'Average Distance from Polling Average (ADPA)',\n",
      "       'Herding Penalty'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505 entries, 0 to 504\n",
      "Data columns (total 21 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   Rank                                          505 non-null    int64  \n",
      " 1   Pollster                                      505 non-null    object \n",
      " 2   Pollster Rating ID                            505 non-null    int64  \n",
      " 3   Polls Analyzed                                505 non-null    int64  \n",
      " 4   NCPP/AAPOR/Roper                              505 non-null    int64  \n",
      " 5   Banned by 538                                 505 non-null    int64  \n",
      " 6   Predictive Plus-Minus                         505 non-null    float64\n",
      " 7   538 Grade                                     505 non-null    object \n",
      " 8   Mean-Reverted Bias                            461 non-null    float64\n",
      " 9   Races Called Correctly                        505 non-null    float64\n",
      " 10  Misses Outside MOE                            505 non-null    float64\n",
      " 11  Simple Average Error                          505 non-null    float64\n",
      " 12  Simple Expected Error                         505 non-null    float64\n",
      " 13  Simple Plus-Minus                             505 non-null    float64\n",
      " 14  Advanced Plus-Minus                           505 non-null    float64\n",
      " 15  Mean-Reverted Advanced Plus Minus             505 non-null    float64\n",
      " 16  # of Polls for Bias Analysis                  505 non-null    int64  \n",
      " 17  Bias                                          461 non-null    float64\n",
      " 18  House Effect                                  443 non-null    float64\n",
      " 19  Average Distance from Polling Average (ADPA)  402 non-null    float64\n",
      " 20  Herding Penalty                               505 non-null    float64\n",
      "dtypes: float64(13), int64(6), object(2)\n",
      "memory usage: 83.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Load the dataset \n",
    "poll = pd.read_csv('pollster-ratings.csv')\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure, this will help identify column names, data types, and get a sense of the data\n",
    "poll.head()\n",
    "\n",
    "# Check the number of rows in your dataset\n",
    "print(poll.shape[0])  # Returns the number of observations.\n",
    "\n",
    "# Check the number of columns in your dataset\n",
    "print(poll.shape[1])  # Returns the number of columns.\n",
    "\n",
    "# Check for missing values in each column.\n",
    "print(poll.isnull().sum())  # Returns the number of missing values per column.\n",
    "\n",
    "# Check the data types of each column\n",
    "print(poll.dtypes)\n",
    "\n",
    "# Check the columns to understand the structure of the dataset\n",
    "print(poll.columns)\n",
    "\n",
    "# Check basic information about the dataset (columns, missing values, data types)\n",
    "print(poll.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f10bce-5e5c-4f51-ba99-57ea1c4424e8",
   "metadata": {},
   "source": [
    "<h3>2. Handle Missing Values by Dropping Rows</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467023f-a5e9-47c4-8257-3c08c3d6f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows for simplicity, but also we could fill missing values using the mean or mode\n",
    "poll = poll.dropna() \n",
    "poll.isnull().sum()\n",
    "\n",
    "# Drop the numeric index column 0\n",
    "poll = poll.drop(poll.columns[0], axis=1)\n",
    "poll.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f3db75-3a6d-4708-97c2-11a512a176ea",
   "metadata": {},
   "source": [
    "<h3>3. Accuracy Before Using the KNN Model (With Raw Data and Missing Values)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbacd755-d17d-4f8e-9fab-32408072a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features (predictors) and outcome (target variable)\n",
    "X_raw = poll[['Polls Analyzed', 'Predictive Plus-Minus', 'Mean-Reverted Bias', \n",
    "            'Races Called Correctly', 'Misses Outside MOE', 'Simple Expected Error', \n",
    "            'Advanced Plus-Minus', 'Bias', 'House Effect']]  # Add more predictors as needed\n",
    "\n",
    "y_raw = poll['Simple Average Error']  # Outcome variable: 'Simple Average Error'\n",
    "\n",
    "# Step 1: Split the raw data into train and test sets (80% train, 20% test)\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the KNN model (using KNeighborsRegressor for regression)\n",
    "model_raw = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the model on raw data (without imputing missing values)\n",
    "model_raw.fit(X_train_raw, y_train_raw)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_raw = model_raw.predict(X_test_raw)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_raw = mean_squared_error(y_test_raw, y_pred_raw)\n",
    "r2_raw = r2_score(y_test_raw, y_pred_raw)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Before Cleaning - Mean Squared Error: {mse_raw}')\n",
    "print(f'Before Cleaning - R-Squared: {r2_raw}')\n",
    "\n",
    "# Before training (raw data)\n",
    "sns.histplot(y_raw, kde=True)\n",
    "plt.title('Distribution of Simple Average Error (Before Training)')\n",
    "plt.xlabel('Simple Average Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot to visualize the prediction vs actual values before training\n",
    "plt.scatter(y_test_raw, y_pred_raw)\n",
    "plt.xlabel('Actual Simple Average Error')\n",
    "plt.ylabel('Predicted Simple Average Error')\n",
    "plt.title('Actual vs Predicted (Before Training)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa46b60-b0db-4f03-b278-71c2efe47702",
   "metadata": {},
   "source": [
    "<h3>4. Accuracy After Using the KNN Model (With Imputation for Missing Values)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac561f-ae73-44bb-8cd1-2a59da975f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features (predictors) and outcome (target variable)\n",
    "X_raw = poll[[ 'Polls Analyzed', 'Predictive Plus-Minus', 'Mean-Reverted Bias', \n",
    "            'Races Called Correctly', 'Misses Outside MOE', 'Simple Expected Error', \n",
    "            'Advanced Plus-Minus', 'Bias', 'House Effect']]  # Add more predictors as needed\n",
    "\n",
    "y_raw = poll['Simple Average Error']  # Outcome variable: 'Simple Average Error'\n",
    "\n",
    "# Step 1: Impute missing values in the predictors using SimpleImputer (mean imputation)\n",
    "imputer = SimpleImputer(strategy='mean')  # Impute missing values with the mean\n",
    "X_raw_imputed = imputer.fit_transform(X_raw)  # Apply imputation to the features\n",
    "\n",
    "# Optionally scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw_imputed)  # Scaling the data\n",
    "\n",
    "# Step 2: Split the cleaned and scaled data into train and test sets (80% train, 20% test)\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(X_scaled, y_raw, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the KNN model (using KNeighborsRegressor for regression)\n",
    "model_clean = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the model on cleaned (imputed) data\n",
    "model_clean.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_clean = model_clean.predict(X_test_clean)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_clean = mean_squared_error(y_test_clean, y_pred_clean)\n",
    "r2_clean = r2_score(y_test_clean, y_pred_clean)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'After Cleaning - Mean Squared Error: {mse_clean}')\n",
    "print(f'After Cleaning - R-Squared: {r2_clean}')\n",
    "\n",
    "# After training (cleaned data)\n",
    "sns.histplot(y_raw, kde=True)\n",
    "plt.title('Distribution of Simple Average Error (After Training)')\n",
    "plt.xlabel('Simple Average Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot to visualize the prediction vs actual values after training\n",
    "plt.scatter(y_test_clean, y_pred_clean)\n",
    "plt.xlabel('Actual Simple Average Error')\n",
    "plt.ylabel('Predicted Simple Average Error')\n",
    "plt.title('Actual vs Predicted (After Training)')\n",
    "plt.show()\n",
    "\n",
    "# Compare model performance before and after cleaning\n",
    "print(f'Accuracy Improvement from Before to After Cleaning: {r2_clean - r2_raw:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d585a06f-2f19-46c7-b7eb-d4030dbe9c48",
   "metadata": {},
   "source": [
    "<font size=\"2\">Before Cleaning (Raw Data):</font>\n",
    "\n",
    "* <font size=\"2\">Mean Squared Error (MSE): Before handling missing values, the KNN model performed poorly with a high MSE, indicating that the model's predictions were far from the actual values.</font>\n",
    "\n",
    "* <font size=\"2\">R-Squared (R²): The R² value was low, suggesting that the model was unable to explain much of the variance in the Simple Average Error using the raw data.</font>\n",
    "\n",
    "<font size=\"2\">After Cleaning (Imputed Data):</font>\n",
    "\n",
    "* <font size=\"2\">Mean Squared Error (MSE): After imputing missing values and scaling the features, the KNN model showed a significant improvement in performance with a lower MSE.</font>\n",
    "\n",
    "* <font size=\"2\">R-Squared (R²): The R² value increased substantially, indicating that the cleaned data provided more predictive power.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57877ea3-3fc5-46ff-9e00-669ccab15af7",
   "metadata": {},
   "source": [
    "<h3>5.Feature Exploration and Correlation Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23426309-379d-49f2-8877-846536408e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the correlation between selected key pollster metrics and visualizes the results in a heatmap.\n",
    "# This helps identify relationships between important polling variables for better analysis and interpretation.\n",
    "\n",
    "# Select key metrics for analysis - these metrics represent important performance indicators for pollsters.\n",
    "key_metrics = [\n",
    "    'Predictive Plus-Minus',    # Accuracy of predictions compared to actual results\n",
    "    'Races Called Correctly',   # Number of races correctly predicted by the pollster\n",
    "    'Simple Average Error',     # The average error between pollster predictions and actual outcomes\n",
    "    'Mean-Reverted Bias',       # Bias after applying mean reversion techniques\n",
    "    'Polls Analyzed',           # Number of polls conducted/analyzed by the pollster\n",
    "    'House Effect'              # The bias a pollster has when reflecting political party preferences\n",
    "]\n",
    "\n",
    "# Generate the correlation matrix for the selected key metrics\n",
    "# This computes the Pearson correlation coefficient between each pair of variables in 'key_metrics'\n",
    "corr_matrix = poll[key_metrics].corr()\n",
    "\n",
    "# Create the heatmap using Seaborn\n",
    "plt.figure(figsize=(8, 6))  # Set figure size for better readability\n",
    "\n",
    "sns.heatmap(corr_matrix, \n",
    "            annot=True,       # Display correlation values in the heatmap cells\n",
    "            cmap='coolwarm',  # Color palette indicating magnitude of correlation\n",
    "            fmt='.2f',        # Format the correlation values to 2 decimal places\n",
    "            square=True,      # Make the heatmap square-shaped for symmetry\n",
    "            center=0)         # Center the color scale at 0 for better contrast between positive and negative correlations\n",
    "\n",
    "# Add a title to the heatmap\n",
    "plt.title('Correlation Heatmap of Key Pollster Metrics')\n",
    "\n",
    "# Adjust layout to ensure everything fits without overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0459a21f-8fd2-4e88-b3b2-348eb1630d1c",
   "metadata": {},
   "source": [
    "<h2> Results</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd39b23-941c-4015-98f7-1b8ca6444968",
   "metadata": {},
   "source": [
    "* <font size=\"2\">Before Cleaning: A scatter plot comparing actual vs predicted values showed that the predictions were scattered without any clear pattern, which is typical of models trained on raw, incomplete data.</font>\n",
    "\n",
    "* <font size=\"2\">After Cleaning: The scatter plot after cleaning showed a clearer correlation between predicted and actual values, indicating that imputing missing values and scaling the data improved model performance.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fae17b-60db-45d8-8cf4-e7dcc5a89e34",
   "metadata": {},
   "source": [
    "<font size=\"2\">Improvement After Cleaning: The performance comparison between the raw data (before cleaning) and the imputed data (after cleaning) showed a clear improvement in both MSE and R². The model's ability to predict Simple Average Error was significantly better once the missing values were addressed.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535dade6-d5aa-4f42-aa23-90e189b615aa",
   "metadata": {},
   "source": [
    " <h2> Discussion</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f52354-5e0f-46b9-bd4e-3048976f7432",
   "metadata": {},
   "source": [
    "<font size=\"2\">The analysis demonstrated that KNN could be effectively used to predict Simple Average Error based on key pollster metrics. Imputing missing values significantly improved the model's performance, as shown by the increase in R² and decrease in MSE. The results suggest that Predictive Plus-Minus, Races Called Correctly, and other metrics are important factors in determining pollster accuracy.</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a848e93-9591-4ea9-8e35-900a1cc30161",
   "metadata": {},
   "source": [
    "<font size=\"2\">Limitations</font>\n",
    "\n",
    "<font size=\"2\">Model Complexity: While KNN is effective for this project, it might not perform as well on larger datasets or more complex data structures. Other models such as Random Forest or Gradient Boosting could be explored for further improvements.</font>\n",
    "\n",
    "<font size=\"2\">Data Bias: The dataset might have biases in terms of which pollsters are included, especially if certain types of pollsters are overrepresented. This could affect the generalizability of the model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbdfbbe-613e-451e-b55f-b6d7cefa06cb",
   "metadata": {},
   "source": [
    "<h2> Conclusion</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d36fb9-24b4-4119-a6f0-cb49d0d77474",
   "metadata": {},
   "source": [
    "<font size=\"2\">This project demonstrated that KNN is a viable method for predicting pollster performance based on available metrics. By addressing missing values and applying appropriate machine learning techniques, we were able to significantly improve model predictions. The insights gained from this analysis can help refine polling methods and enhance the reliability of future predictions.</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8deb502-675b-4f9a-ab01-2ff1482f28c9",
   "metadata": {},
   "source": [
    "<h2> Refreneces</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558042d-2413-4f3c-99fe-bb81a1d30949",
   "metadata": {},
   "source": [
    "* <font size=\"2\"> Kennedy, C., et al. (2021). \"Enhancing Polling Accuracy through Real-Time Adjustments.\" Public Opinion Quarterly.</font>\n",
    "* <font size=\"2\"> Silver, N. (2022). \"Modern Challenges in Political Forecasting.\" Journal of Predictive Analytics.</font>\n",
    "* <font size=\"2\"> Green, T., et al. (2023). \"Hybrid Models for Improved Election Polling.\" Journal of Data Science and Elections.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7535ac-417f-4205-b546-bb94e42818d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
